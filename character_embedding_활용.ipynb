{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "character embedding 활용.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ExIMHgTPFfND"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data preprocessing\n",
        "## import lib"
      ],
      "metadata": {
        "id": "NMp8NtExFWeu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NN4FZXz86vad"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) load data and remove duplicated data\n"
      ],
      "metadata": {
        "id": "ExIMHgTPFfND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('ner_dataset.csv', encoding='latin1')"
      ],
      "metadata": {
        "id": "_pYHmeSu7Ke8"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6etuPiHQ7udn",
        "outputId": "549e0b82-5270-4436-f9f8-efc5ff2ad9c2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of           Sentence #           Word  POS Tag\n",
              "0        Sentence: 1      Thousands  NNS   O\n",
              "1                NaN             of   IN   O\n",
              "2                NaN  demonstrators  NNS   O\n",
              "3                NaN           have  VBP   O\n",
              "4                NaN        marched  VBN   O\n",
              "...              ...            ...  ...  ..\n",
              "1048570          NaN           they  PRP   O\n",
              "1048571          NaN      responded  VBD   O\n",
              "1048572          NaN             to   TO   O\n",
              "1048573          NaN            the   DT   O\n",
              "1048574          NaN         attack   NN   O\n",
              "\n",
              "[1048575 rows x 4 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' # of rows : {len(data)}')\n",
        "print(f' null in datas : {data.isnull().values.any()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrAIx5lC9JDn",
        "outputId": "a83fe8cc-76c4-4e61-b39c-ce6cec8e0abf"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " # of rows : 1048575\n",
            " null in datas : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'# null in data')\n",
        "print('-'*20)\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkVJN3FL9hsi",
        "outputId": "8f0850af-f948-4f17-ef87-d85dbade8fc4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# null in data\n",
            "--------------------\n",
            "Sentence #    1000616\n",
            "Word                0\n",
            "POS                 0\n",
            "Tag                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'rm duplicated data[\\'sencence\\'] : {data[\"Sentence #\"].nunique()}')\n",
        "print(f'rm duplicated data[\\'Word\\'] : {data.Word.nunique()}')\n",
        "print(f'rm duplicated data[\\'Tag\\'] : {data.Tag.nunique()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXrj7DHg-Dqc",
        "outputId": "5a773f7a-7d08-4564-cb64-0a17f9f8774a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm duplicated data['sencence'] : 47959\n",
            "rm duplicated data['Word'] : 35178\n",
            "rm duplicated data['Tag'] : 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BIO 표현 방법에서 아무런 태깅도 의미하지 않는 O가 가장 887,908개로 가장 많은 개수를 차지함을 볼 수 있습니다."
      ],
      "metadata": {
        "id": "Eo1gsy53CZHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tag count table')\n",
        "print('-'*20)\n",
        "print(data.groupby('Tag').size().reset_index(name='count'))\n",
        "# groupby object unpacking\n",
        "#for i in data.groupby('Tag'):\n",
        "#  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCEjUEpQ-hQ1",
        "outputId": "72014211-7092-4eb6-e35c-1c6702d3b0ad"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag count table\n",
            "--------------------\n",
            "      Tag   count\n",
            "0   B-art     402\n",
            "1   B-eve     308\n",
            "2   B-geo   37644\n",
            "3   B-gpe   15870\n",
            "4   B-nat     201\n",
            "5   B-org   20143\n",
            "6   B-per   16990\n",
            "7   B-tim   20333\n",
            "8   I-art     297\n",
            "9   I-eve     253\n",
            "10  I-geo    7414\n",
            "11  I-gpe     198\n",
            "12  I-nat      51\n",
            "13  I-org   16784\n",
            "14  I-per   17251\n",
            "15  I-tim    6528\n",
            "16      O  887908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- fillna(method='ffill')을 활용하여 null 값을 가진 바로 이전행의 값으로 초기화\n",
        "  * ffill : front fill로 추정"
      ],
      "metadata": {
        "id": "ue0fLnncCq87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.fillna(method='ffill')\n",
        "print(data[-5:-1])\n",
        "print(data.isnull().any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqqNRwBB_5Bn",
        "outputId": "3058890d-55e6-44f9-cf68-931024b18a66"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Sentence #       Word  POS Tag\n",
            "1048570  Sentence: 47959       they  PRP   O\n",
            "1048571  Sentence: 47959  responded  VBD   O\n",
            "1048572  Sentence: 47959         to   TO   O\n",
            "1048573  Sentence: 47959        the   DT   O\n",
            "Sentence #    False\n",
            "Word          False\n",
            "POS           False\n",
            "Tag           False\n",
            "dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 대문자->소문자(문자의 갯수를 줄이기 위함, 어차피 같은 뜻이기도 함)"
      ],
      "metadata": {
        "id": "de2qJ_3IDrTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'before upper to lower, rm duplicated of data[\\'Word\\'] : {data.Word.nunique()}')\n",
        "data['Word'] = data['Word'].str.lower()\n",
        "print(f'after upper to lower, rm duplicated of data[\\'Word\\'] : {data.Word.nunique()}')\n",
        "data[-6:-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "roRAPSucDBPe",
        "outputId": "5a01f0e4-ad4a-471a-ba0e-51a9891be291"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before upper to lower, rm duplicated of data['Word'] : 35178\n",
            "after upper to lower, rm duplicated of data['Word'] : 31817\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Sentence #       Word  POS Tag\n",
              "1048569  Sentence: 47959       said  VBD   O\n",
              "1048570  Sentence: 47959       they  PRP   O\n",
              "1048571  Sentence: 47959  responded  VBD   O\n",
              "1048572  Sentence: 47959         to   TO   O\n",
              "1048573  Sentence: 47959        the   DT   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c7c250c-36c5-45f6-9c0d-ea371a6dcbe1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1048569</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>said</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048570</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>they</td>\n",
              "      <td>PRP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048571</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>responded</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048572</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048573</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c7c250c-36c5-45f6-9c0d-ea371a6dcbe1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c7c250c-36c5-45f6-9c0d-ea371a6dcbe1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c7c250c-36c5-45f6-9c0d-ea371a6dcbe1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) transform tagging infos to integer incoding, EDA"
      ],
      "metadata": {
        "id": "YJelFen7XHKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문장에 등장한 단어와 Tag 정보끼리 페어링"
      ],
      "metadata": {
        "id": "DeGNxW86RcHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_func = lambda temp: [(w,t) for w,t in zip(temp['Word'].values.tolist(), temp['Tag'].values.tolist())]\n",
        "\n",
        "print(f'before total sample count : {data.isnull().sum()[\"Sentence #\"]}') # 1000616\n",
        "tagged_sentences = [t for t in data.groupby('Sentence #').apply(lambda_func)]\n",
        "print(f'after total sample count : {len(tagged_sentences)}')\n",
        "print(f'sample : {tagged_sentences[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58UAcHR-RlCl",
        "outputId": "42edf7c6-a5c9-4157-b3fb-6d1a43bccf1f"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before total sample count : 0\n",
            "after total sample count : 47959\n",
            "sample : [('thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('london', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('british', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습을 시키기 위해 단어와 tag 정보 분리"
      ],
      "metadata": {
        "id": "q2_3Aj97UT_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences, ner_tags = list(), list()\n",
        "\n",
        "for tagged_sentence in tagged_sentences:\n",
        "\n",
        "  s, t = zip(*tagged_sentence)\n",
        "  #unpacking item type == tuple\n",
        "  #Tokenizer.fit_on_text 내부에서 lower() 수행하기 때문에 tuple로 들어가면 안됨\n",
        "  sentences.append(list(s))\n",
        "  ner_tags.append(list(t))"
      ],
      "metadata": {
        "id": "LDug-JzyUk93"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 전체 데이터의 문장 길이 분포 확인\n",
        "  - 0에서 40 사이로 분포하고 있음"
      ],
      "metadata": {
        "id": "oysX-NDNVHFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'longest sentence len: {max(len(s) for s in sentences)}')\n",
        "print(f'mean sentence len: {sum(map(len, sentences))/len(sentences)}')\n",
        "plt.hist([len(s) for s in sentences], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "5aGzXA3RVMuI",
        "outputId": "46b1d05b-f7a7-4088-9df2-0d2f2a6b0eaf"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "longest sentence len: 104\n",
            "mean sentence len: 21.863987989741236\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- keras tokenizer 를 활용한 정수 인코딩"
      ],
      "metadata": {
        "id": "hl6pvSuEYCY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 단어 사용, idx[1] = OOV\n",
        "src_tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "src_tokenizer.fit_on_texts(sentences)\n",
        "# tag 정보 대문자 유지\n",
        "tar_tokenizer = Tokenizer(lower=False)\n",
        "tar_tokenizer.fit_on_texts(ner_tags)\n",
        "\n",
        "vocab_size = len(src_tokenizer.word_index) + 1\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "print(f'word_vocab len : {vocab_size}\\ntag_vocab len : {tag_size}')\n",
        "print(f'idx of OOV : {src_tokenizer.word_index[\"OOV\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrk21N1xYGtK",
        "outputId": "fcda4af7-91f8-436f-c0b2-2bc8936ece61"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_vocab len : 31819\n",
            "tag_vocab len : 18\n",
            "idx of OOV : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 정수 인코딩 진행"
      ],
      "metadata": {
        "id": "sfGg_LK9fKKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
        "Y_data = tar_tokenizer.texts_to_sequences(ner_tags)\n",
        "\n",
        "print(X_data[0])\n",
        "print(Y_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW1gFQDqlArW",
        "outputId": "150f7d3e-f805-41b7-da07-523c28a04ca5"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[254, 6, 967, 16, 1795, 238, 468, 7, 523, 2, 129, 5, 61, 9, 571, 2, 833, 6, 186, 90, 22, 15, 56, 3]\n",
            "[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 훈련 후, 결과 확인을 위한 변수 지정\n",
        "  - index_to_word : 인덱스로부터 단어 리턴\n",
        "  - index_to_ner : 인덱스로부터 tag 리턴"
      ],
      "metadata": {
        "id": "sXXLF2WXlWD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = src_tokenizer.word_index\n",
        "index_to_word = src_tokenizer.index_word\n",
        "\n",
        "ner_to_index = tar_tokenizer.word_index\n",
        "index_to_ner = tar_tokenizer.index_word\n",
        "index_to_ner[0] = \"PAD\"\n",
        "\n",
        "index_to_ner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE_YmKcUlp4T",
        "outputId": "a890aac5-4b1b-48a9-d7e8-a367690f00b0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'PAD',\n",
              " 1: 'O',\n",
              " 2: 'B-geo',\n",
              " 3: 'B-tim',\n",
              " 4: 'B-org',\n",
              " 5: 'I-per',\n",
              " 6: 'B-per',\n",
              " 7: 'I-org',\n",
              " 8: 'B-gpe',\n",
              " 9: 'I-geo',\n",
              " 10: 'I-tim',\n",
              " 11: 'B-art',\n",
              " 12: 'B-eve',\n",
              " 13: 'I-art',\n",
              " 14: 'I-eve',\n",
              " 15: 'B-nat',\n",
              " 16: 'I-gpe',\n",
              " 17: 'I-nat'}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 문자 임베딩을 위한 preprocessing"
      ],
      "metadata": {
        "id": "o9F1VaYkFvJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문자와 매핑된 정수를 각각 임베딩 층을 거치도록 하여, 문자 단위의 임베딩을 얻어낸다\n",
        "  - 전체 데이터의 모든 단어를 문자 레벨로 분해 -> 문자 집합 생성"
      ],
      "metadata": {
        "id": "-GplLNDoGOr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = list(set(data['Word'].values))\n",
        "chars = set([char for word in words for char in word])\n",
        "chars = sorted(list(chars))\n",
        "print('char set elements')\n",
        "print('-'*50)\n",
        "for i in range(len(chars)//9):\n",
        "  print(chars[i*9:i*9+9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbP_YflYFzK2",
        "outputId": "1f1b5c5f-2127-44b8-86ac-320f469b3781"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "char set elements\n",
            "--------------------------------------------------\n",
            "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')']\n",
            "['+', ',', '-', '.', '/', '0', '1', '2', '3']\n",
            "['4', '5', '6', '7', '8', '9', ':', ';', '?']\n",
            "['@', '[', ']', '_', '`', 'a', 'b', 'c', 'd']\n",
            "['e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm']\n",
            "['n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v']\n",
            "['w', 'x', 'y', 'z', '~', '\\x85', '\\x91', '\\x92', '\\x93']\n",
            "['\\x94', '\\x96', '\\x97', '\\xa0', '°', 'é', 'ë', 'ö', 'ü']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 딕셔너리 생성\n",
        "  - char to index\n",
        "  - index to char"
      ],
      "metadata": {
        "id": "xnoxT9dlJHcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_idx = {val : idx+2 for idx,val in enumerate(chars)}\n",
        "char_to_idx[\"OOV\"] = 1\n",
        "char_to_idx[\"PAD\"] = 0\n",
        "\n",
        "idx_to_char = {}\n",
        "for k,v in char_to_idx.items():\n",
        "  idx_to_char[v] = k"
      ],
      "metadata": {
        "id": "vZAhlkHMGzmW"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문자의 최대 길이를 15로 제한한 후, 그 미만의 문장 패딩 추가\n",
        "  - post padding 하는 이유?"
      ],
      "metadata": {
        "id": "AmFjZIu0Nw5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_sentence = 15\n",
        "\n",
        "def padding_char_indice(char_indice:list, max_len_sentence:int):\n",
        "  return pad_sequences(char_indice, maxlen=max_len_sentence, padding='post', value=0)\n",
        "\n",
        "# word to sequence and padding\n",
        "def integer_coding(sentences):\n",
        "  char_data = []\n",
        "  for sentence in sentences:\n",
        "    word_indice = [word_to_index[word] for word in sentence]\n",
        "    char_indice = [[char_to_idx[char] for char in word] for word in sentence]\n",
        "    char_indice = padding_char_indice(char_indice, max_len_sentence)\n",
        "\n",
        "    for char_token in char_indice:\n",
        "      if len(char_token) > max_len_sentence:\n",
        "        continue\n",
        "    char_data.append(char_indice)\n",
        "  return char_data\n",
        "\n",
        "X_char_data = integer_coding(sentences)"
      ],
      "metadata": {
        "id": "4WWIOTmmJ1Rp"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('before\\tafter')\n",
        "for bef, af in zip(sentences[0], X_data[0]):\n",
        "  print(f'{bef}\\t{af}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI9_wWomd8t4",
        "outputId": "653d5932-60c2-46fe-da78-849c129949f7"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before\tafter\n",
            "thousands\t254\n",
            "of\t6\n",
            "demonstrators\t967\n",
            "have\t16\n",
            "marched\t1795\n",
            "through\t238\n",
            "london\t468\n",
            "to\t7\n",
            "protest\t523\n",
            "the\t2\n",
            "war\t129\n",
            "in\t5\n",
            "iraq\t61\n",
            "and\t9\n",
            "demand\t571\n",
            "the\t2\n",
            "withdrawal\t833\n",
            "of\t6\n",
            "british\t186\n",
            "troops\t90\n",
            "from\t22\n",
            "that\t15\n",
            "country\t56\n",
            ".\t3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'len of X_char_data[0]\\'s col len:{len(X_char_data[0][0])}')\n",
        "print(X_char_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCmmwPrhebPH",
        "outputId": "b976177c-c605-4fe4-8a85-b4a0f540bdad"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len of X_char_data[0]'s col len:15\n",
            "[[53 41 48 54 52 34 47 37 52  0  0  0  0  0  0]\n",
            " [48 39  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [37 38 46 48 47 52 53 51 34 53 48 51 52  0  0]\n",
            " [41 34 55 38  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [46 34 51 36 41 38 37  0  0  0  0  0  0  0  0]\n",
            " [53 41 51 48 54 40 41  0  0  0  0  0  0  0  0]\n",
            " [45 48 47 37 48 47  0  0  0  0  0  0  0  0  0]\n",
            " [53 48  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [49 51 48 53 38 52 53  0  0  0  0  0  0  0  0]\n",
            " [53 41 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [56 34 51  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 47  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [42 51 34 50  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [34 47 37  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [37 38 46 34 47 37  0  0  0  0  0  0  0  0  0]\n",
            " [53 41 38  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [56 42 53 41 37 51 34 56 34 45  0  0  0  0  0]\n",
            " [48 39  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [35 51 42 53 42 52 41  0  0  0  0  0  0  0  0]\n",
            " [53 51 48 48 49 52  0  0  0  0  0  0  0  0  0]\n",
            " [39 51 48 46  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [53 41 34 53  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [36 48 54 47 53 51 58  0  0  0  0  0  0  0  0]\n",
            " [14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Data split"
      ],
      "metadata": {
        "id": "09vSoZvBuERC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- max_len(70) 만큼 패딩 진행 및 train/test set 분리"
      ],
      "metadata": {
        "id": "nsp365q5ng9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 70\n",
        "# padding to sequence\n",
        "X_data = pad_sequences(X_data, maxlen=max_len, padding='post', value=0)\n",
        "Y_data = pad_sequences(Y_data, maxlen=max_len, padding='post', value=0)\n",
        "X_char_data = pad_sequences(X_char_data, maxlen=max_len, padding='post', value=0)"
      ],
      "metadata": {
        "id": "6hJtylzUmgq4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split train/test data\n",
        "X_train, X_test, Y_train_int, Y_test_int = train_test_split(X_data, Y_data, test_size=.2, random_state=777)\n",
        "X_char_train, X_char_test, _, _ = train_test_split(X_char_data, Y_data, test_size=.2, random_state=777)\n",
        "\n",
        "X_char_train = np.array(X_char_train)\n",
        "X_char_test = np.array(X_char_test)"
      ],
      "metadata": {
        "id": "F7Icq9otn5q2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one-hot encoding to tag info\n",
        "Y_train = to_categorical(Y_train_int, num_classes=tag_size)\n",
        "Y_test = to_categorical(Y_test_int, num_classes=tag_size)"
      ],
      "metadata": {
        "id": "UjFI4UNltXij"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'first word of sentence\\' 150th : {index_to_word[150]}')\n",
        "\n",
        "for col in X_char_train[0]:\n",
        "  for idx in col:\n",
        "    if idx != 0:\n",
        "      print(idx_to_char[idx], end='')\n",
        "  print(end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vktA2MMqohx9",
        "outputId": "931e0d1c-a293-424d-de04-7a8df9b58eed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first word of sentence' 150th : soldiers\n",
            "soldiers returned fire with artillery and machine guns and a gun battle broke out .                                                        "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 각 데이터와 레이블의 크기 확인"
      ],
      "metadata": {
        "id": "mgG_Zj6oqa2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
        "print('훈련 샘플 레이블의 크기 : {}'.format(Y_train.shape))\n",
        "print('훈련 샘플 char 데이터의 크기 : {}'.format(X_char_train.shape))\n",
        "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
        "print('테스트 샘플 레이블의 크기 : {}'.format(Y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYlrtEGTpC2f",
        "outputId": "ff40a6c1-2b24-48bb-8272-29d489b54df3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 샘플 문장의 크기 : (38367, 70)\n",
            "훈련 샘플 레이블의 크기 : (38367, 70, 18)\n",
            "훈련 샘플 char 데이터의 크기 : (38367, 70, 15)\n",
            "테스트 샘플 문장의 크기 : (9592, 70)\n",
            "테스트 샘플 레이블의 크기 : (9592, 70, 18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5TI3U39gs5Cr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. BiLSTM-CNN을 이용한 개체명 인식\n",
        "## import lib"
      ],
      "metadata": {
        "id": "ZjaWV_7UudI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval\n",
        "!pip install keras-crf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dZ6qErHIUn5",
        "outputId": "3e61bc0c-719d-47ef-9244-d92212d3400e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=fa48c1a13279f6f3804d31df5aede232def66191ff82500e24a595b6cfc129af\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-crf\n",
            "  Downloading keras_crf-0.3.0-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-crf) (2.8.2+zzzcolab20220527125636)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (4.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (0.5.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (14.0.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.46.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (0.26.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-crf) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras-crf) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-crf) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-crf) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-crf) (3.2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->keras-crf) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->keras-crf) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons->keras-crf) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons, keras-crf\n",
            "Successfully installed keras-crf-0.3.0 tensorflow-addons-0.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Input, TimeDistributed, Dropout, concatenate, Bidirectional, LSTM, Conv1D, Dense, MaxPooling1D, Flatten\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.initializers import RandomUniform\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from seqeval.metrics import f1_score, classification_report\n",
        "from keras_crf import CRFModel"
      ],
      "metadata": {
        "id": "SA9Vhr-BuhQF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define fields & models"
      ],
      "metadata": {
        "id": "iPI5-yBYJdXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "char_embedding_dim = 64\n",
        "dropout_ratio = 0.5\n",
        "hidden_units = 256\n",
        "num_filters = 30\n",
        "kernel_size =3"
      ],
      "metadata": {
        "id": "uixJkK40Jhc2"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 단어 임베딩"
      ],
      "metadata": {
        "id": "UwWYR71fJwBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_ids = Input(shape=(None,), dtype='int32', name='words_input')\n",
        "word_embeddings = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(word_ids)"
      ],
      "metadata": {
        "id": "GCpgr9KEJsdG"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- char embedding"
      ],
      "metadata": {
        "id": "W-0qlNSCKG0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_ids = Input(shape=(None, max_len_sentence,), name='char_input')\n",
        "embed_char_out = TimeDistributed(\n",
        "    Embedding(len(char_to_idx), char_embedding_dim, embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), \n",
        "    name='char_embedding')(char_ids)\n",
        "dropout = Dropout(dropout_ratio)(embed_char_out)"
      ],
      "metadata": {
        "id": "4n-K2nESKDpv"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- char embedding 에 Conv1D 수행"
      ],
      "metadata": {
        "id": "vJka2qvNLC0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv1d_out = TimeDistributed(\n",
        "    Conv1D(\n",
        "        kernel_size=kernel_size,\n",
        "        filters=num_filters,\n",
        "        padding='same',\n",
        "        activation='tanh',\n",
        "        strides=1),\n",
        "        name='Conv1D')(dropout)\n",
        "\n",
        "maxpool_out = TimeDistributed(\n",
        "    MaxPooling1D(max_len_sentence),\n",
        "    name='MaxPool1D'\n",
        ")(conv1d_out)\n",
        "\n",
        "char_embeddings = TimeDistributed(Flatten(), name='Flatten')(maxpool_out)\n",
        "char_embeddings = Dropout(dropout_ratio)(char_embeddings)"
      ],
      "metadata": {
        "id": "aI8_PlwQK_B-"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- char embedding 에 conv1d 수행한 결과를 단어 임베딩과 concatenate"
      ],
      "metadata": {
        "id": "wDL8SHRMMNgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = concatenate([word_embeddings, char_embeddings])"
      ],
      "metadata": {
        "id": "Y0r_fzLmMMEZ"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 연결된 output 백터를 문장의 길이만큼 BiLSTM 만들기"
      ],
      "metadata": {
        "id": "WVvE2W72McUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = Bidirectional(\n",
        "    LSTM(\n",
        "        hidden_units,\n",
        "         return_sequences=True,\n",
        "         dropout=dropout_ratio\n",
        "    )\n",
        ")(output)"
      ],
      "metadata": {
        "id": "QO5MEbqXMa5c"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 출력층"
      ],
      "metadata": {
        "id": "p5lDYv5vMzYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = TimeDistributed(\n",
        "    Dense(\n",
        "        tag_size,\n",
        "        activation='softmax',\n",
        "\n",
        "    ),\n",
        "    name='Dense'\n",
        ")(output)"
      ],
      "metadata": {
        "id": "C40kWauyMx9h"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(\n",
        "    inputs = [word_ids, char_ids],\n",
        "    outputs=[output]\n",
        ")\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='nadam',\n",
        "    metrics=['acc']\n",
        ")"
      ],
      "metadata": {
        "id": "bXBKLflGM-AE"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr1tfZnviF-m",
        "outputId": "78d42f50-3f79-4f53-cb8d-74fa3c6e5866"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " char_input (InputLayer)        [(None, None, 15)]   0           []                               \n",
            "                                                                                                  \n",
            " char_embedding (TimeDistribute  (None, None, 15, 64  4736       ['char_input[0][0]']             \n",
            " d)                             )                                                                 \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, None, 15, 64  0           ['char_embedding[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv1D (TimeDistributed)       (None, None, 15, 30  5790        ['dropout_6[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " MaxPool1D (TimeDistributed)    (None, None, 1, 30)  0           ['Conv1D[0][0]']                 \n",
            "                                                                                                  \n",
            " words_input (InputLayer)       [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " Flatten (TimeDistributed)      (None, None, 30)     0           ['MaxPool1D[0][0]']              \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, None, 128)    4072832     ['words_input[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, None, 30)     0           ['Flatten[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, None, 158)    0           ['embedding_5[0][0]',            \n",
            "                                                                  'dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_7 (Bidirectional  (None, None, 512)   849920      ['concatenate_5[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " time_distributed_16 (TimeDistr  (None, None, 18)    9234        ['bidirectional_7[0][0]']        \n",
            " ibuted)                                                                                          \n",
            "                                                                                                  \n",
            " Dense (TimeDistributed)        (None, None, 18)     342         ['time_distributed_16[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,942,854\n",
            "Trainable params: 4,942,854\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train model(weight file 있는 경우 실행할 필요 없음)\n",
        "- early stopping callback 설정\n"
      ],
      "metadata": {
        "id": "oHesQidINhXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1,\n",
        "    patience=4\n",
        ")\n",
        "\n",
        "mc = ModelCheckpoint(\n",
        "    'bilstm_cnn.h5',\n",
        "    monitor='val_acc',\n",
        "    mode='max',\n",
        "    verbose=1,\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "# batch_size= 128, epoch=15, val_data_ratio = 10%\n",
        "history = model.fit(\n",
        "    [X_train, X_char_train], Y_train,\n",
        "    batch_size=128, epochs=15, validation_split=0.1,\n",
        "    verbose=1, callbacks=[es,mc]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glY4FHKlNYm0",
        "outputId": "f5999d91-94d9-421a-b4b7-1328da7f1156"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.2063 - acc: 0.9474\n",
            "Epoch 1: val_acc improved from -inf to 0.97518, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 526s 2s/step - loss: 0.2063 - acc: 0.9474 - val_loss: 0.0881 - val_acc: 0.9752\n",
            "Epoch 2/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0650 - acc: 0.9815\n",
            "Epoch 2: val_acc improved from 0.97518 to 0.98367, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 427s 2s/step - loss: 0.0650 - acc: 0.9815 - val_loss: 0.0549 - val_acc: 0.9837\n",
            "Epoch 3/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0461 - acc: 0.9865\n",
            "Epoch 3: val_acc improved from 0.98367 to 0.98624, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 439s 2s/step - loss: 0.0461 - acc: 0.9865 - val_loss: 0.0458 - val_acc: 0.9862\n",
            "Epoch 4/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0385 - acc: 0.9885\n",
            "Epoch 4: val_acc improved from 0.98624 to 0.98706, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 429s 2s/step - loss: 0.0385 - acc: 0.9885 - val_loss: 0.0421 - val_acc: 0.9871\n",
            "Epoch 5/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0341 - acc: 0.9897\n",
            "Epoch 5: val_acc improved from 0.98706 to 0.98753, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 437s 2s/step - loss: 0.0341 - acc: 0.9897 - val_loss: 0.0409 - val_acc: 0.9875\n",
            "Epoch 6/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0310 - acc: 0.9905\n",
            "Epoch 6: val_acc did not improve from 0.98753\n",
            "270/270 [==============================] - 437s 2s/step - loss: 0.0310 - acc: 0.9905 - val_loss: 0.0404 - val_acc: 0.9875\n",
            "Epoch 7/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0283 - acc: 0.9911\n",
            "Epoch 7: val_acc did not improve from 0.98753\n",
            "270/270 [==============================] - 435s 2s/step - loss: 0.0283 - acc: 0.9911 - val_loss: 0.0408 - val_acc: 0.9873\n",
            "Epoch 8/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0264 - acc: 0.9916\n",
            "Epoch 8: val_acc did not improve from 0.98753\n",
            "270/270 [==============================] - 436s 2s/step - loss: 0.0264 - acc: 0.9916 - val_loss: 0.0414 - val_acc: 0.9874\n",
            "Epoch 9/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0248 - acc: 0.9920\n",
            "Epoch 9: val_acc improved from 0.98753 to 0.98765, saving model to bilstm_cnn.h5\n",
            "270/270 [==============================] - 441s 2s/step - loss: 0.0248 - acc: 0.9920 - val_loss: 0.0413 - val_acc: 0.9876\n",
            "Epoch 10/15\n",
            "270/270 [==============================] - ETA: 0s - loss: 0.0233 - acc: 0.9925\n",
            "Epoch 10: val_acc did not improve from 0.98765\n",
            "270/270 [==============================] - 437s 2s/step - loss: 0.0233 - acc: 0.9925 - val_loss: 0.0413 - val_acc: 0.9875\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## get results\n",
        "- validation data 에 대해 정확도가 가장 높았던 모델 테스트"
      ],
      "metadata": {
        "id": "4jnlng7zglCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load model\n",
        "model = load_model('bilstm_cnn.h5')\n",
        "\n",
        "# test data index\n",
        "i = 13\n",
        "y_predicted = model.predict([np.array([X_test[i]]), np.array([X_char_test[i]])])\n",
        "\n",
        "# 확률 벡터 -> 정수값으로 변경\n",
        "y_predicted = np.argmax(y_predicted, axis=-1)\n",
        "labels = np.argmax(Y_test[i], -1)\n",
        "\n",
        "print(f'단어\\t\\t실제값\\t예측값')\n",
        "print('-'*50)\n",
        "\n",
        "for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):\n",
        "  # word = 'PAD' 인 경우 제외\n",
        "  if word !=0:\n",
        "    print(f'{index_to_word[word]:17}:\\t{index_to_ner[tag]}\\t{index_to_ner[pred]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppq7ymzXOUVi",
        "outputId": "ddcf15b0-5e5c-4034-bbe2-eebcbc7d03de"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어\t\t실제값\t예측값\n",
            "--------------------------------------------------\n",
            "the              :\tO\tO\n",
            "statement        :\tO\tO\n",
            "came             :\tO\tO\n",
            "as               :\tO\tO\n",
            "u.n.             :\tB-org\tB-org\n",
            "secretary-general:\tI-org\tI-org\n",
            "kofi             :\tB-per\tB-per\n",
            "annan            :\tI-per\tI-per\n",
            "met              :\tO\tO\n",
            "with             :\tO\tO\n",
            "officials        :\tO\tO\n",
            "in               :\tO\tO\n",
            "amman            :\tB-geo\tB-geo\n",
            "to               :\tO\tO\n",
            "discuss          :\tO\tO\n",
            "wednesday        :\tB-tim\tB-tim\n",
            "'s               :\tO\tO\n",
            "attacks          :\tO\tO\n",
            ".                :\tO\tO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 테스트 데이터(test set)에 대해 성능 측정"
      ],
      "metadata": {
        "id": "5-TjlDexi6ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sequences_to_tag(sequences):\n",
        "    result = []\n",
        "    # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
        "    for sequence in sequences:\n",
        "        word_sequence = []\n",
        "        # 시퀀스로부터 확률 벡터 또는 원-핫 벡터를 하나씩 꺼낸다.\n",
        "        for pred in sequence:\n",
        "            # 정수로 변환. 예를 들어 pred가 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
        "            pred_index = np.argmax(pred)            \n",
        "            # index_to_ner을 사용하여 정수를 태깅 정보로 변환. 'PAD'는 'O'로 변경.\n",
        "            word_sequence.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))\n",
        "        result.append(word_sequence)\n",
        "    return result"
      ],
      "metadata": {
        "id": "ENuQ8LMkkW6b"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict([X_test, X_char_test])\n",
        "pred_tags = sequences_to_tag(y_predicted)\n",
        "test_tags = sequences_to_tag(Y_test)\n",
        "\n",
        "print(f'f1-score : {f1_score(test_tags, pred_tags):.1%}')\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k-Z3AwDipea",
        "outputId": "88f45ecb-8adf-40cd-8eca-c5ff5fd4ef56"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1-score : 79.2%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        63\n",
            "         eve       0.44      0.27      0.33        52\n",
            "         geo       0.84      0.85      0.84      7620\n",
            "         gpe       0.95      0.95      0.95      3145\n",
            "         nat       0.47      0.19      0.27        37\n",
            "         org       0.60      0.57      0.58      4033\n",
            "         per       0.74      0.72      0.73      3545\n",
            "         tim       0.86      0.84      0.85      4067\n",
            "\n",
            "   micro avg       0.80      0.78      0.79     22562\n",
            "   macro avg       0.61      0.55      0.57     22562\n",
            "weighted avg       0.80      0.78      0.79     22562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. BiLSTM-CNN-CRF"
      ],
      "metadata": {
        "id": "IgnI7POgV5TI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- CRF 층을 추가한 모델과 문자 임베딩을 모두 활용한 모델의 성능 파악"
      ],
      "metadata": {
        "id": "qKPFH976V-uP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define fields & model"
      ],
      "metadata": {
        "id": "imK9gv1yWRGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fields"
      ],
      "metadata": {
        "id": "6YZVgI6VWXq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "char_embedding_dim = 64\n",
        "dropout_ratio = 0.5\n",
        "hidden_units = 256\n",
        "num_filters = 30\n",
        "kernel_size = 3"
      ],
      "metadata": {
        "id": "sxq47Uqmjcte"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 단어 임베딩"
      ],
      "metadata": {
        "id": "mcveheWkWj_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_ids = Input(shape=(None,), dtype='int32', name='words_input')\n",
        "word_embeddings = Embedding(\n",
        "    input_dim=vocab_size,\n",
        "    output_dim=embedding_dim)(word_ids)"
      ],
      "metadata": {
        "id": "XO5rl-1iWiTA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 캐릭터 임베딩"
      ],
      "metadata": {
        "id": "eF-Myjk3W3gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_ids = Input(\n",
        "    shape=(None, max_len_sentence),\n",
        "    name = 'char_input'\n",
        ")\n",
        "embed_char_out = TimeDistributed(\n",
        "    Embedding(\n",
        "        len(char_to_idx),\n",
        "        char_embedding_dim,\n",
        "        embeddings_initializer=RandomUniform(\n",
        "            minval=-0.5, maxval=0.5\n",
        "        )\n",
        "    ),\n",
        "    name='char_embedding')(char_ids)\n",
        "dropout = Dropout(dropout_ratio)(embed_char_out)"
      ],
      "metadata": {
        "id": "S2EMc49PW2Ya"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Conv1D to char embedding"
      ],
      "metadata": {
        "id": "SbpWazfqX6Mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv1d_out = TimeDistributed(\n",
        "    Conv1D(\n",
        "        kernel_size=kernel_size,\n",
        "        filters=num_filters,\n",
        "        padding='same',\n",
        "        activation='tanh',\n",
        "        strides=1))(dropout)\n",
        "maxpool_out = TimeDistributed(\n",
        "    MaxPooling1D(max_len_sentence))(conv1d_out)\n",
        "\n",
        "char_embeddings = TimeDistributed(Flatten())(maxpool_out)\n",
        "char_embeddings = Dropout(dropout_ratio)(char_embeddings)\n",
        "\n",
        "output = concatenate([word_embeddings, char_embeddings])"
      ],
      "metadata": {
        "id": "hRnGx2TYXz8F"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 연결한 벡터를 문장 길이만큼 BiLSTM 수행"
      ],
      "metadata": {
        "id": "ZJlnG4OuaI6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = Bidirectional(\n",
        "    LSTM(\n",
        "        hidden_units,\n",
        "         return_sequences=True,\n",
        "         dropout = dropout_ratio\n",
        "    )\n",
        ")(output)"
      ],
      "metadata": {
        "id": "db5OKsaQZj1X"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 출력층"
      ],
      "metadata": {
        "id": "X0_2ZqxCaRBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = TimeDistributed(Dense(tag_size, activation='relu'))(output)"
      ],
      "metadata": {
        "id": "wcHiSv5KaPyu"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define model"
      ],
      "metadata": {
        "id": "0o7tGAT3abAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base = Model(\n",
        "    inputs=[word_ids, char_ids],\n",
        "    outputs=[output]\n",
        ")\n",
        "model = CRFModel(base, tag_size)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    metrics='accuracy'\n",
        ")\n",
        "\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1,\n",
        "    patience=4\n",
        ")\n",
        "mc = ModelCheckpoint(\n",
        "    'bilstm_cnn_crf/cp.ckpt',\n",
        "    monitor='val_decode_sequence_accuracy',\n",
        "    mode='max',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "jk1GOxT4aZ7x"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train model\n",
        "- CRF layer 는 one-hot encoding 된 label 을 지원하지 않으므로 y_train_int 사용"
      ],
      "metadata": {
        "id": "plCRzCNtbPJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#diff Y_train, Y_train_int\n",
        "print(Y_train[0])\n",
        "print(Y_train_int[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am8rMvj9bNj9",
        "outputId": "c6617881-1c23-41dd-a1e2-4f9d1c0b10c5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    [X_train, X_char_train], Y_train_int,\n",
        "    batch_size= 128,\n",
        "    epochs=15,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[mc, es]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av8nXwiybgYZ",
        "outputId": "11613bc2-a3e5-4c3a-957b-3ec8edaab16e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9422 - loss: 17.5997\n",
            "Epoch 1: val_decode_sequence_accuracy improved from -inf to 0.96929, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 563s 2s/step - decode_sequence_accuracy: 0.9422 - loss: 17.5631 - val_decode_sequence_accuracy: 0.9693 - val_loss: 7.5107\n",
            "Epoch 2/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9762 - loss: 5.3899\n",
            "Epoch 2: val_decode_sequence_accuracy improved from 0.96929 to 0.97966, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 476s 2s/step - decode_sequence_accuracy: 0.9762 - loss: 5.3842 - val_decode_sequence_accuracy: 0.9797 - val_loss: 4.7122\n",
            "Epoch 3/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9837 - loss: 3.3867\n",
            "Epoch 3: val_decode_sequence_accuracy improved from 0.97966 to 0.98402, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 476s 2s/step - decode_sequence_accuracy: 0.9837 - loss: 3.3871 - val_decode_sequence_accuracy: 0.9840 - val_loss: 3.3106\n",
            "Epoch 4/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9866 - loss: 2.6058\n",
            "Epoch 4: val_decode_sequence_accuracy improved from 0.98402 to 0.98557, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 473s 2s/step - decode_sequence_accuracy: 0.9866 - loss: 2.6052 - val_decode_sequence_accuracy: 0.9856 - val_loss: 2.8637\n",
            "Epoch 5/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9880 - loss: 2.1930\n",
            "Epoch 5: val_decode_sequence_accuracy did not improve from 0.98557\n",
            "270/270 [==============================] - 472s 2s/step - decode_sequence_accuracy: 0.9880 - loss: 2.1915 - val_decode_sequence_accuracy: 0.9853 - val_loss: 2.7840\n",
            "Epoch 6/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9889 - loss: 1.9154\n",
            "Epoch 6: val_decode_sequence_accuracy improved from 0.98557 to 0.98571, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 474s 2s/step - decode_sequence_accuracy: 0.9889 - loss: 1.9149 - val_decode_sequence_accuracy: 0.9857 - val_loss: 2.6146\n",
            "Epoch 7/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9895 - loss: 1.7239\n",
            "Epoch 7: val_decode_sequence_accuracy improved from 0.98571 to 0.98582, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 476s 2s/step - decode_sequence_accuracy: 0.9895 - loss: 1.7238 - val_decode_sequence_accuracy: 0.9858 - val_loss: 2.4664\n",
            "Epoch 8/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9899 - loss: 1.5717\n",
            "Epoch 8: val_decode_sequence_accuracy improved from 0.98582 to 0.98592, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 475s 2s/step - decode_sequence_accuracy: 0.9899 - loss: 1.5709 - val_decode_sequence_accuracy: 0.9859 - val_loss: 2.5304\n",
            "Epoch 9/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9903 - loss: 1.4393\n",
            "Epoch 9: val_decode_sequence_accuracy improved from 0.98592 to 0.98619, saving model to bilstm_cnn_crf/cp.ckpt\n",
            "270/270 [==============================] - 474s 2s/step - decode_sequence_accuracy: 0.9903 - loss: 1.4395 - val_decode_sequence_accuracy: 0.9862 - val_loss: 2.4046\n",
            "Epoch 10/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9906 - loss: 1.3313\n",
            "Epoch 10: val_decode_sequence_accuracy did not improve from 0.98619\n",
            "270/270 [==============================] - 473s 2s/step - decode_sequence_accuracy: 0.9906 - loss: 1.3318 - val_decode_sequence_accuracy: 0.9859 - val_loss: 2.4848\n",
            "Epoch 11/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9909 - loss: 1.2427\n",
            "Epoch 11: val_decode_sequence_accuracy did not improve from 0.98619\n",
            "270/270 [==============================] - 477s 2s/step - decode_sequence_accuracy: 0.9909 - loss: 1.2412 - val_decode_sequence_accuracy: 0.9861 - val_loss: 2.4530\n",
            "Epoch 12/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9912 - loss: 1.1686\n",
            "Epoch 12: val_decode_sequence_accuracy did not improve from 0.98619\n",
            "270/270 [==============================] - 479s 2s/step - decode_sequence_accuracy: 0.9912 - loss: 1.1675 - val_decode_sequence_accuracy: 0.9854 - val_loss: 2.4985\n",
            "Epoch 13/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9914 - loss: 1.0987\n",
            "Epoch 13: val_decode_sequence_accuracy did not improve from 0.98619\n",
            "270/270 [==============================] - 480s 2s/step - decode_sequence_accuracy: 0.9914 - loss: 1.0977 - val_decode_sequence_accuracy: 0.9856 - val_loss: 2.4585\n",
            "Epoch 13: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결과 확인"
      ],
      "metadata": {
        "id": "-GxHAk3N1gK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 가장 결과가 좋은 가중치 load, predict"
      ],
      "metadata": {
        "id": "Y6jkiSgV1lbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('bilstm_cnn_crf/cp.ckpt')\n",
        "\n",
        "i = 13\n",
        "Y_predicted = model.predict(\n",
        "    [np.array([X_test[i]]), np.array([X_char_test[i]])])[0]\n",
        "labels = np.argmax(Y_test[i], -1)"
      ],
      "metadata": {
        "id": "XFhp6ZVGbvTQ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'단어\\t\\t실제값\\t예측값')\n",
        "print('-'*50)\n",
        "\n",
        "for word, tag, pred in zip(X_test[i], labels, Y_predicted[0]):\n",
        "  # PAD 제외\n",
        "  if word != 0:\n",
        "    print(f'{index_to_word[word]:19}{index_to_ner[tag]:7}{index_to_ner[pred]}')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PrarYyF10j5",
        "outputId": "88e19a35-f75e-40e5-f191-f6612fb14a09"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어\t\t실제값\t예측값\n",
            "--------------------------------------------------\n",
            "the                O      O\n",
            "statement          O      O\n",
            "came               O      O\n",
            "as                 O      O\n",
            "u.n.               B-org  B-org\n",
            "secretary-general  I-org  I-org\n",
            "kofi               B-per  B-per\n",
            "annan              I-per  I-per\n",
            "met                O      O\n",
            "with               O      O\n",
            "officials          O      O\n",
            "in                 O      O\n",
            "amman              B-geo  B-geo\n",
            "to                 O      O\n",
            "discuss            O      O\n",
            "wednesday          B-tim  B-tim\n",
            "'s                 O      O\n",
            "attacks            O      O\n",
            ".                  O      O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 테스트 데이터 성능 측정"
      ],
      "metadata": {
        "id": "p7XvVrJ9AL6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sequences_to_tag_for_crf(sequences): \n",
        "    result = []\n",
        "    # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
        "    for sequence in sequences: \n",
        "        word_sequence = []\n",
        "        # 시퀀스로부터 예측 정수 레이블을 하나씩 꺼낸다.\n",
        "        for pred_index in sequence:\n",
        "            # index_to_ner을 사용하여 정수를 태깅 정보로 변환. 'PAD'는 'O'로 변경.\n",
        "            word_sequence.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))\n",
        "        result.append(word_sequence)\n",
        "    return result\n",
        "\n",
        "Y_predicted = model.predict(\n",
        "    [X_test, X_char_test]\n",
        ")[0]\n",
        "\n",
        "pred_tags = sequences_to_tag_for_crf(Y_predicted)\n",
        "test_tags = sequences_to_tag(Y_test)\n",
        "\n",
        "print(f'f1-score : {f1_score(test_tags, pred_tags):.1%}')\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw8n31L6-OrL",
        "outputId": "0500b1c6-dd35-4094-d71a-3bbc91e82ae7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1-score : 81.1%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        63\n",
            "         eve       0.55      0.31      0.40        52\n",
            "         geo       0.85      0.85      0.85      7620\n",
            "         gpe       0.95      0.94      0.95      3145\n",
            "         nat       1.00      0.08      0.15        37\n",
            "         org       0.67      0.60      0.63      4033\n",
            "         per       0.79      0.73      0.76      3545\n",
            "         tim       0.87      0.85      0.86      4067\n",
            "\n",
            "   micro avg       0.83      0.79      0.81     22562\n",
            "   macro avg       0.71      0.55      0.57     22562\n",
            "weighted avg       0.82      0.79      0.81     22562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.BiLSTM-BiLSTM-CRF"
      ],
      "metadata": {
        "id": "zRgLSRfDDM7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "char_embedding_dim = 64\n",
        "dropout_ratio = 0.3\n",
        "hidden_units = 64\n",
        "\n",
        "# 단어 임베딩\n",
        "word_ids = Input(batch_shape=(None, None), dtype='int32', name='word_input')\n",
        "word_embeddings = Embedding(input_dim=vocab_size,\n",
        "                                        output_dim=embedding_dim,\n",
        "                                        name='word_embedding')(word_ids)\n",
        "\n",
        "# char 임베딩\n",
        "char_ids = Input(batch_shape=(None, None, None), dtype='int32', name='char_input')\n",
        "char_embeddings = Embedding(input_dim=(len(char_to_idx)),\n",
        "                                        output_dim=char_embedding_dim,\n",
        "                                        embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5),\n",
        "                                        name='char_embedding')(char_ids)\n",
        "\n",
        "# char 임베딩을 BiLSTM을 통과 시켜 단어 벡터를 얻고 단어 임베딩과 연결\n",
        "char_embeddings = TimeDistributed(Bidirectional(LSTM(hidden_units)))(char_embeddings)\n",
        "output = concatenate([word_embeddings, char_embeddings])\n",
        "\n",
        "# 연결한 벡터를 가지고 문장의 길이만큼 LSTM을 수행\n",
        "output = Dropout(dropout_ratio)(output)\n",
        "output = Bidirectional(LSTM(units=hidden_units, return_sequences=True))(output)\n",
        "\n",
        "# 출력층\n",
        "output = TimeDistributed(Dense(tag_size, activation='relu'))(output)\n",
        "\n",
        "base = Model(inputs=[word_ids, char_ids], outputs=[output])\n",
        "model = CRFModel(base, tag_size)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), metrics='accuracy')\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('bilstm_bilstm_crf/cp.ckpt', monitor='val_decode_sequence_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "history = model.fit([X_train, X_char_train], Y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3OzxI8dCHg4",
        "outputId": "5dc076dc-43c8-4ce7-9fac-1d94541d1599"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9298 - loss: 22.1273\n",
            "Epoch 1: val_decode_sequence_accuracy improved from -inf to 0.96477, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 651s 2s/step - decode_sequence_accuracy: 0.9298 - loss: 22.0729 - val_decode_sequence_accuracy: 0.9648 - val_loss: 7.6636\n",
            "Epoch 2/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9783 - loss: 4.8422\n",
            "Epoch 2: val_decode_sequence_accuracy improved from 0.96477 to 0.98380, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 635s 2s/step - decode_sequence_accuracy: 0.9783 - loss: 4.8368 - val_decode_sequence_accuracy: 0.9838 - val_loss: 3.4269\n",
            "Epoch 3/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9860 - loss: 2.8967\n",
            "Epoch 3: val_decode_sequence_accuracy improved from 0.98380 to 0.98555, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 635s 2s/step - decode_sequence_accuracy: 0.9860 - loss: 2.8967 - val_decode_sequence_accuracy: 0.9855 - val_loss: 2.8520\n",
            "Epoch 4/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9881 - loss: 2.3003\n",
            "Epoch 4: val_decode_sequence_accuracy improved from 0.98555 to 0.98659, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 635s 2s/step - decode_sequence_accuracy: 0.9881 - loss: 2.3010 - val_decode_sequence_accuracy: 0.9866 - val_loss: 2.5070\n",
            "Epoch 5/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9894 - loss: 1.9367\n",
            "Epoch 5: val_decode_sequence_accuracy did not improve from 0.98659\n",
            "270/270 [==============================] - 637s 2s/step - decode_sequence_accuracy: 0.9894 - loss: 1.9380 - val_decode_sequence_accuracy: 0.9865 - val_loss: 2.6301\n",
            "Epoch 6/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9902 - loss: 1.6920\n",
            "Epoch 6: val_decode_sequence_accuracy did not improve from 0.98659\n",
            "270/270 [==============================] - 638s 2s/step - decode_sequence_accuracy: 0.9902 - loss: 1.6920 - val_decode_sequence_accuracy: 0.9864 - val_loss: 2.5525\n",
            "Epoch 7/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9907 - loss: 1.5273\n",
            "Epoch 7: val_decode_sequence_accuracy improved from 0.98659 to 0.98669, saving model to bilstm_bilstm_crf/cp.ckpt\n",
            "270/270 [==============================] - 636s 2s/step - decode_sequence_accuracy: 0.9907 - loss: 1.5267 - val_decode_sequence_accuracy: 0.9867 - val_loss: 2.5999\n",
            "Epoch 8/15\n",
            "270/270 [==============================] - ETA: 0s - decode_sequence_accuracy: 0.9914 - loss: 1.3654\n",
            "Epoch 8: val_decode_sequence_accuracy did not improve from 0.98669\n",
            "270/270 [==============================] - 640s 2s/step - decode_sequence_accuracy: 0.9914 - loss: 1.3641 - val_decode_sequence_accuracy: 0.9865 - val_loss: 2.7849\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model 검증\n"
      ],
      "metadata": {
        "id": "S18PZ5wDZ8Yf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- load weight and sample test"
      ],
      "metadata": {
        "id": "_MI8CAppZ_-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('bilstm_bilstm_crf/cp.ckpt')\n",
        "\n",
        "i = 13\n",
        "Y_predicted = model.predict(\n",
        "    [np.array([X_test[i]]), np.array([X_char_test[i]])]\n",
        ")[0]\n",
        "labels = np.argmax(Y_test[i], -1)\n",
        "\n",
        "print(f'단어\\t\\t실제값\\t예측값')\n",
        "print('-'*50)\n",
        "\n",
        "for word, tag, pred in zip(X_test[i], labels, Y_predicted[0]):\n",
        "  # PAD 제외\n",
        "  if word != 0:\n",
        "    print(f'{index_to_word[word]:19}{index_to_ner[tag]:7}{index_to_ner[pred]}')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk3AMloEDWI9",
        "outputId": "e960efef-7413-4190-ecff-0d5f3ff413a0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어\t\t실제값\t예측값\n",
            "--------------------------------------------------\n",
            "the                O      O\n",
            "statement          O      O\n",
            "came               O      O\n",
            "as                 O      O\n",
            "u.n.               B-org  B-org\n",
            "secretary-general  I-org  I-org\n",
            "kofi               B-per  B-per\n",
            "annan              I-per  I-per\n",
            "met                O      O\n",
            "with               O      O\n",
            "officials          O      O\n",
            "in                 O      O\n",
            "amman              B-geo  B-geo\n",
            "to                 O      O\n",
            "discuss            O      O\n",
            "wednesday          B-tim  B-tim\n",
            "'s                 O      O\n",
            "attacks            O      O\n",
            ".                  O      O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- test data 성능 측정"
      ],
      "metadata": {
        "id": "4HmWLzK-aqTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_predicted = model.predict([X_test, X_char_test])[0]\n",
        "pred_tags = sequences_to_tag_for_crf(Y_predicted)\n",
        "test_tags = sequences_to_tag(Y_test)\n",
        "\n",
        "print(f'f1-score : {f1_score(test_tags, pred_tags):.1%}')\n",
        "print(classification_report(test_tags, pred_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU7iUBDSZ5Sp",
        "outputId": "0a34a57e-00f0-4777-e888-10945ba456a2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1-score : 81.1%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         art       0.00      0.00      0.00        63\n",
            "         eve       0.50      0.29      0.37        52\n",
            "         geo       0.84      0.85      0.85      7620\n",
            "         gpe       0.95      0.95      0.95      3145\n",
            "         nat       0.33      0.08      0.13        37\n",
            "         org       0.69      0.57      0.63      4033\n",
            "         per       0.80      0.74      0.77      3545\n",
            "         tim       0.89      0.83      0.86      4067\n",
            "\n",
            "   micro avg       0.83      0.79      0.81     22562\n",
            "   macro avg       0.62      0.54      0.57     22562\n",
            "weighted avg       0.83      0.79      0.81     22562\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3-YUc4AvbEqA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}